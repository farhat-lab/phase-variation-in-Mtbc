{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vcf\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "from os.path import exists\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.patches import Rectangle\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from itertools import compress\n",
    "from pylab import MaxNLocator\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib import gridspec\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import Bio\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.Blast.Applications import NcbiblastnCommandline\n",
    "from Bio.Blast import NCBIXML\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from Bio import pairwise2\n",
    "from Bio import SeqIO\n",
    "from Bio.Graphics import GenomeDiagram\n",
    "from Bio.SeqUtils import GC\n",
    "from Bio import Phylo\n",
    "\n",
    "from Bio.Align.Applications import MuscleCommandline\n",
    "from StringIO import StringIO\n",
    "from Bio import AlignIO\n",
    "from Bio.Align import AlignInfo\n",
    "from Bio.Seq import MutableSeq\n",
    "from collections import Counter\n",
    "\n",
    "#for exporting to Adobe Illustrator\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [A] SNVS PER GENE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1] *Functions* to get mutation events from branches given a tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_mutations_on_branch_SNV(branch_length_i, num_sites_to_construct_tree, locus_length):\n",
    "    \n",
    "    '''\n",
    "    This function takes a branch length as INPUT and OUTPUTs\n",
    "    (1) the number of neutral mutations that occur on this branch length \n",
    "    by drawing from a poisson distribution and (2) a list of the chromosomal\n",
    "    positions that are mutated (drawn randomly from across the chromosome).\n",
    "    '''\n",
    "    \n",
    "    # get molecular clock rate (mu_i) to convert branch length into years\n",
    "    mu_i = np.random.uniform(low=0.3, high=0.6)\n",
    "\n",
    "    # get t_i, the branch length in years\n",
    "    t_i = (branch_length_i * num_sites_to_construct_tree) / mu_i\n",
    "\n",
    "    # get the mutation rate for neutral mutations (nu_i) to calculate lambda\n",
    "    nu_i = np.random.uniform(low=0.3, high=0.6)\n",
    "    \n",
    "    # normalize mutation rate for the length of the gene/locus\n",
    "    nu_i = nu_i * (float(locus_length)/ 4000000.0)\n",
    "\n",
    "    # calculate lambda, parameter for poisson distribution\n",
    "    lambda_i = t_i * nu_i\n",
    "\n",
    "    # draw from poisson distribution to get the number of neutral mutations that occurred on this branch\n",
    "    num_mutations_i = np.random.poisson(lam=lambda_i)\n",
    "    \n",
    "    # choose number drawn above positions from range(0, length of locus) that were \"mutated\", choose the H37Rv ref positions that mutated randomly\n",
    "    positions_mutated_i = np.random.randint(low=1, high=locus_length+1, size=num_mutations_i)\n",
    "    \n",
    "    return positions_mutated_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mutation_events_from_tree_branches(num_sites_to_construct_tree, isolate_group, locus_length_dict, locus_count_dict):\n",
    "\n",
    "    # Load in PHYLOGENY\n",
    "    #########################################################################################################\n",
    "    # We're going to use Biopython's Phylo module to load phylogenetic trees created by Luca\n",
    "    \n",
    "    phylogeny_path = '/n/data1/hms/dbmi/farhat/Roger/homoplasy_project/phylogenies/tree_output_files/phylogeny_lineage_' + isolate_group + '/tree_lineage_' + isolate_group + '_iqtree_FINAL.treefile'\n",
    "\n",
    "    # parses and load tree\n",
    "    tree = Phylo.parse(phylogeny_path , 'newick').next() \n",
    "\n",
    "    # root the tree with the outgroup M. canettii [\"Normally you will want the outgroup to be a monophyletic group, rather than a single taxon.\"]\n",
    "    tree.root_with_outgroup({\"name\":\"canettii\"})\n",
    "\n",
    "    # flip branches so deeper clades are displayed at top\n",
    "    tree.ladderize()\n",
    "\n",
    "    # TERMINAL BRANCHES\n",
    "    #########################################################################################################\n",
    "    # retrieves the terminal nodes of the tree\n",
    "    terminal_nodes = tree.get_terminals()\n",
    "\n",
    "    # Lengths of terminal branches\n",
    "    terminal_branch_length_list = [terminal_nodes[i].branch_length for i in range(0 , len(terminal_nodes))][1:]\n",
    "\n",
    "    # retrieve Sample IDs that were used for this tree\n",
    "    isolate_tags_in_phylogeny = [terminal_nodes[i].name for i in range(0 , len(terminal_nodes))]\n",
    "    \n",
    "    # iterate through each LOCUS & get list of positions mutated\n",
    "    for locus_i in locus_length_dict.keys():\n",
    "\n",
    "        # iterate through each branch-length & collect\n",
    "        # (1) the chromosomal positions of the mutations \n",
    "        mutation_positions_across_terminal_branches_list = []\n",
    "\n",
    "        for branch_length_i in terminal_branch_length_list:\n",
    "\n",
    "            mutation_positions_per_branch_i = num_mutations_on_branch_SNV(branch_length_i, num_sites_to_construct_tree, locus_length_dict[locus_i])\n",
    "\n",
    "            mutation_positions_across_terminal_branches_list = mutation_positions_across_terminal_branches_list + list(mutation_positions_per_branch_i)\n",
    "\n",
    "        # Counter dict for the number of times each chromosomal position is mutated\n",
    "        mutation_events_per_pos_from_terminal_dict = Counter(mutation_positions_across_terminal_branches_list)\n",
    "        \n",
    "        # update this in Counter dict for LOCUS\n",
    "        locus_count_dict[locus_i] = locus_count_dict[locus_i] + mutation_events_per_pos_from_terminal_dict\n",
    "\n",
    "    # INTERNAL BRANCHES\n",
    "    #########################################################################################################\n",
    "    # retrieves the internal nodes of the tree\n",
    "    internal_nodes = tree.get_nonterminals() \n",
    "\n",
    "    # Lengths of internal branches\n",
    "    internal_branch_length_list = [internal_nodes[i].branch_length for i in range(0 , len(internal_nodes))][2:]\n",
    "    \n",
    "    # iterate through each LOCUS & get list of positions mutated\n",
    "    for locus_i in locus_length_dict.keys():\n",
    "\n",
    "        # iterate through each branch-length & collect\n",
    "        # (1) the chromosomal positions of the mutations \n",
    "        mutation_positions_across_internal_branches_list = []\n",
    "\n",
    "        for branch_length_i in internal_branch_length_list:\n",
    "\n",
    "            mutation_positions_per_branch_i = num_mutations_on_branch_SNV(branch_length_i, num_sites_to_construct_tree, locus_length_dict[locus_i])\n",
    "\n",
    "            mutation_positions_across_internal_branches_list = mutation_positions_across_internal_branches_list + list(mutation_positions_per_branch_i)\n",
    "\n",
    "        # Counter dict for the number of times each chromosomal position is mutated\n",
    "        mutation_events_per_pos_from_internal_dict = Counter(mutation_positions_across_internal_branches_list)\n",
    "        \n",
    "        # update this in Counter dict for LOCUS\n",
    "        locus_count_dict[locus_i] = locus_count_dict[locus_i] + mutation_events_per_pos_from_internal_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [2] Simulate for each LOCUS and save results of simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load dictionary with (corrected) lengths for each gene we compute mutational density for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/n/data1/hms/dbmi/farhat/Roger/homoplasy_project/pickled_files/mutational_density_simulations_per_locus/locus_length_dict.pickle', 'rb') as handle:\n",
    "    locus_length_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2.1] Simulate mutation events for each tree and aggregate across trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input \n",
    "sim_i = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolate_group_list = ['1','2','3','4A','4B','4C','5','6']\n",
    "\n",
    "# sites used to construct each tree\n",
    "num_sites_to_construct_tree_dict = {'1':243940.0, '2':243542.0, '3':188741.0, '4A':213804.0, '4B':207271.0, '4C':203590.0, '5':33818.0, '6':36923.0}\n",
    "\n",
    "# create a Counter dict for each locus to keep track of positions mutated (and now many times)\n",
    "locus_count_dict = {}\n",
    "for locus_i in locus_length_dict.keys():\n",
    "    locus_count_dict[locus_i] = Counter()\n",
    "\n",
    "for isolate_group_i in isolate_group_list:\n",
    "\n",
    "    get_mutation_events_from_tree_branches(num_sites_to_construct_tree_dict[isolate_group_i], isolate_group_i, locus_length_dict, locus_count_dict)\n",
    "    \n",
    "# iterate through each LOCUS and create a series of the sum of mutations (sum Hs for each position mutated)\n",
    "Hs_score_per_locus = pd.Series()\n",
    "for locus_i in locus_count_dict.keys():\n",
    "    \n",
    "    Hs_score_per_locus[locus_i] = float(pd.Series(locus_count_dict[locus_i]).sum())\n",
    "\n",
    "# give series a name according to which simulation # it is\n",
    "Hs_score_per_locus.name = 'S'+sim_i\n",
    "\n",
    "# store pandas series for downstream analysis\n",
    "with open('/n/data1/hms/dbmi/farhat/Roger/homoplasy_project/pickled_files/mutational_density_simulations_per_locus/simulation_results/sim_'+sim_i+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(Hs_score_per_locus, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] Submit script for each simulation as job to O2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slurmpy import Slurm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_1 : 51970840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970841\n",
      "submitted: Submitted batch job 51970842\n",
      "submitted: Submitted batch job 51970843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_2 : 51970841\n",
      "LOCUS_sim_3 : 51970842\n",
      "LOCUS_sim_4 : 51970843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970844\n",
      "submitted: Submitted batch job 51970845\n",
      "submitted: Submitted batch job 51970846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_5 : 51970844\n",
      "LOCUS_sim_6 : 51970845\n",
      "LOCUS_sim_7 : 51970846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970847\n",
      "submitted: Submitted batch job 51970848\n",
      "submitted: Submitted batch job 51970849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_8 : 51970847\n",
      "LOCUS_sim_9 : 51970848\n",
      "LOCUS_sim_10 : 51970849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970850\n",
      "submitted: Submitted batch job 51970851\n",
      "submitted: Submitted batch job 51970852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_11 : 51970850\n",
      "LOCUS_sim_12 : 51970851\n",
      "LOCUS_sim_13 : 51970852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970853\n",
      "submitted: Submitted batch job 51970854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_14 : 51970853\n",
      "LOCUS_sim_15 : 51970854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970858\n",
      "submitted: Submitted batch job 51970859\n",
      "submitted: Submitted batch job 51970860\n",
      "submitted: Submitted batch job 51970861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_16 : 51970858\n",
      "LOCUS_sim_17 : 51970859\n",
      "LOCUS_sim_18 : 51970860\n",
      "LOCUS_sim_19 : 51970861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_20 : 51970862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970863\n",
      "submitted: Submitted batch job 51970864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_21 : 51970863\n",
      "LOCUS_sim_22 : 51970864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970874\n",
      "submitted: Submitted batch job 51970875\n",
      "submitted: Submitted batch job 51970876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_23 : 51970874\n",
      "LOCUS_sim_24 : 51970875\n",
      "LOCUS_sim_25 : 51970876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970877\n",
      "submitted: Submitted batch job 51970878\n",
      "submitted: Submitted batch job 51970879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_26 : 51970877\n",
      "LOCUS_sim_27 : 51970878\n",
      "LOCUS_sim_28 : 51970879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970880\n",
      "submitted: Submitted batch job 51970881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_29 : 51970880\n",
      "LOCUS_sim_30 : 51970881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970882\n",
      "submitted: Submitted batch job 51970883\n",
      "submitted: Submitted batch job 51970884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_31 : 51970882\n",
      "LOCUS_sim_32 : 51970883\n",
      "LOCUS_sim_33 : 51970884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970885\n",
      "submitted: Submitted batch job 51970886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_34 : 51970885\n",
      "LOCUS_sim_35 : 51970886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_36 : 51970887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_37 : 51970888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970889\n",
      "submitted: Submitted batch job 51970890\n",
      "submitted: Submitted batch job 51970891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_38 : 51970889\n",
      "LOCUS_sim_39 : 51970890\n",
      "LOCUS_sim_40 : 51970891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970892\n",
      "submitted: Submitted batch job 51970893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_41 : 51970892\n",
      "LOCUS_sim_42 : 51970893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970894\n",
      "submitted: Submitted batch job 51970895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_43 : 51970894\n",
      "LOCUS_sim_44 : 51970895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970896\n",
      "submitted: Submitted batch job 51970897\n",
      "submitted: Submitted batch job 51970898\n",
      "submitted: Submitted batch job 51970899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_45 : 51970896\n",
      "LOCUS_sim_46 : 51970897\n",
      "LOCUS_sim_47 : 51970898\n",
      "LOCUS_sim_48 : 51970899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970900\n",
      "submitted: Submitted batch job 51970901\n",
      "submitted: Submitted batch job 51970902\n",
      "submitted: Submitted batch job 51970903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_49 : 51970900\n",
      "LOCUS_sim_50 : 51970901\n",
      "LOCUS_sim_51 : 51970902\n",
      "LOCUS_sim_52 : 51970903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970904\n",
      "submitted: Submitted batch job 51970905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_53 : 51970904\n",
      "LOCUS_sim_54 : 51970905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970906\n",
      "submitted: Submitted batch job 51970907\n",
      "submitted: Submitted batch job 51970908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_55 : 51970906\n",
      "LOCUS_sim_56 : 51970907\n",
      "LOCUS_sim_57 : 51970908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970909\n",
      "submitted: Submitted batch job 51970910\n",
      "submitted: Submitted batch job 51970911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_58 : 51970909\n",
      "LOCUS_sim_59 : 51970910\n",
      "LOCUS_sim_60 : 51970911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970912\n",
      "submitted: Submitted batch job 51970913\n",
      "submitted: Submitted batch job 51970914\n",
      "submitted: Submitted batch job 51970915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_61 : 51970912\n",
      "LOCUS_sim_62 : 51970913\n",
      "LOCUS_sim_63 : 51970914\n",
      "LOCUS_sim_64 : 51970915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970916\n",
      "submitted: Submitted batch job 51970917\n",
      "submitted: Submitted batch job 51970918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_65 : 51970916\n",
      "LOCUS_sim_66 : 51970917\n",
      "LOCUS_sim_67 : 51970918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970919\n",
      "submitted: Submitted batch job 51970920\n",
      "submitted: Submitted batch job 51970921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_68 : 51970919\n",
      "LOCUS_sim_69 : 51970920\n",
      "LOCUS_sim_70 : 51970921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970922\n",
      "submitted: Submitted batch job 51970923\n",
      "submitted: Submitted batch job 51970924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_71 : 51970922\n",
      "LOCUS_sim_72 : 51970923\n",
      "LOCUS_sim_73 : 51970924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970925\n",
      "submitted: Submitted batch job 51970926\n",
      "submitted: Submitted batch job 51970927\n",
      "submitted: Submitted batch job 51970928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_74 : 51970925\n",
      "LOCUS_sim_75 : 51970926\n",
      "LOCUS_sim_76 : 51970927\n",
      "LOCUS_sim_77 : 51970928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970929\n",
      "submitted: Submitted batch job 51970930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_78 : 51970929\n",
      "LOCUS_sim_79 : 51970930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970931\n",
      "submitted: Submitted batch job 51970932\n",
      "submitted: Submitted batch job 51970933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_80 : 51970931\n",
      "LOCUS_sim_81 : 51970932\n",
      "LOCUS_sim_82 : 51970933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970934\n",
      "submitted: Submitted batch job 51970935\n",
      "submitted: Submitted batch job 51970936\n",
      "submitted: Submitted batch job 51970937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_83 : 51970934\n",
      "LOCUS_sim_84 : 51970935\n",
      "LOCUS_sim_85 : 51970936\n",
      "LOCUS_sim_86 : 51970937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970938\n",
      "submitted: Submitted batch job 51970939\n",
      "submitted: Submitted batch job 51970940\n",
      "submitted: Submitted batch job 51970941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_87 : 51970938\n",
      "LOCUS_sim_88 : 51970939\n",
      "LOCUS_sim_89 : 51970940\n",
      "LOCUS_sim_90 : 51970941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970942\n",
      "submitted: Submitted batch job 51970943\n",
      "submitted: Submitted batch job 51970944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_91 : 51970942\n",
      "LOCUS_sim_92 : 51970943\n",
      "LOCUS_sim_93 : 51970944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970945\n",
      "submitted: Submitted batch job 51970946\n",
      "submitted: Submitted batch job 51970947\n",
      "submitted: Submitted batch job 51970948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS_sim_94 : 51970945\n",
      "LOCUS_sim_95 : 51970946\n",
      "LOCUS_sim_96 : 51970947\n",
      "LOCUS_sim_97 : 51970948\n",
      "LOCUS_sim_98 : 51970949\n",
      "LOCUS_sim_99 : 51970950\n",
      "LOCUS_sim_100 : 51970951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 51970949\n",
      "submitted: Submitted batch job 51970950\n",
      "submitted: Submitted batch job 51970951\n"
     ]
    }
   ],
   "source": [
    "for sim_i in range(1, 101):\n",
    "\n",
    "    LOCUS_sims_job = 'python /home/rv76/Farhat_Lab/Python_Scripts/homoplasy_project/simulations_SNVs_per_gene.py ' + str(sim_i)\n",
    "\n",
    "    #directory where you want output + error files\n",
    "    os.chdir('/n/data1/hms/dbmi/farhat/Roger/homoplasy_project/pickled_files/muts_per_LOCUS_sims_homoplasy_score_jobs')\n",
    "\n",
    "    job_name = 'LOCUS_sim_' + str(sim_i)\n",
    "\n",
    "    s = Slurm(job_name , {'partition':'short' , 'account':'farhat', 'N':'1' , 'time':'0-2:00:00' , 'mem':'16G' , 'mail-type':'FAIL' , 'mail-user':'roger_vargas@g.harvard.edu'})\n",
    "\n",
    "    #submits the job\n",
    "    job_id = s.run(LOCUS_sims_job)\n",
    "\n",
    "    print job_name  + ' : ' +  str(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] Load series of homoplasy score counts across each locus for each simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hs_score_per_locus_sims = []\n",
    "for sim_i in range(1, 101):\n",
    "    \n",
    "    with open('/n/data1/hms/dbmi/farhat/Roger/homoplasy_project/pickled_files/mutational_density_simulations_per_locus/simulation_results/sim_' + str(sim_i) + '.pickle', 'rb') as handle:\n",
    "        Hs_score_per_locus = pickle.load(handle)\n",
    "    \n",
    "    Hs_score_per_locus_sims.append(Hs_score_per_locus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hs_score_per_locus_sims_df = pd.concat(Hs_score_per_locus_sims, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>S7</th>\n",
       "      <th>S8</th>\n",
       "      <th>S9</th>\n",
       "      <th>S10</th>\n",
       "      <th>...</th>\n",
       "      <th>S91</th>\n",
       "      <th>S92</th>\n",
       "      <th>S93</th>\n",
       "      <th>S94</th>\n",
       "      <th>S95</th>\n",
       "      <th>S96</th>\n",
       "      <th>S97</th>\n",
       "      <th>S98</th>\n",
       "      <th>S99</th>\n",
       "      <th>S100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rv0239</th>\n",
       "      <td>82.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rv0238</th>\n",
       "      <td>249.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>...</td>\n",
       "      <td>267.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rv1322</th>\n",
       "      <td>137.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>143.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rv2928</th>\n",
       "      <td>351.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>...</td>\n",
       "      <td>321.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rv1324</th>\n",
       "      <td>379.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>...</td>\n",
       "      <td>428.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           S1     S2     S3     S4     S5     S6     S7     S8     S9    S10  \\\n",
       "Rv0239   82.0   89.0   96.0  115.0  107.0  103.0  114.0   85.0   93.0  108.0   \n",
       "Rv0238  249.0  294.0  279.0  268.0  235.0  261.0  244.0  250.0  290.0  253.0   \n",
       "Rv1322  137.0  139.0  120.0  127.0  118.0  139.0  146.0  133.0  120.0  140.0   \n",
       "Rv2928  351.0  341.0  294.0  324.0  334.0  322.0  295.0  336.0  332.0  314.0   \n",
       "Rv1324  379.0  361.0  429.0  359.0  395.0  398.0  391.0  407.0  405.0  390.0   \n",
       "\n",
       "        ...      S91    S92    S93    S94    S95    S96    S97    S98    S99  \\\n",
       "Rv0239  ...    108.0  109.0   97.0   98.0   93.0  106.0   83.0  102.0   92.0   \n",
       "Rv0238  ...    267.0  240.0  258.0  288.0  313.0  276.0  288.0  276.0  282.0   \n",
       "Rv1322  ...    143.0  145.0  119.0  134.0  125.0  125.0  135.0  135.0  138.0   \n",
       "Rv2928  ...    321.0  310.0  338.0  337.0  313.0  321.0  312.0  337.0  328.0   \n",
       "Rv1324  ...    428.0  394.0  403.0  417.0  387.0  416.0  370.0  402.0  363.0   \n",
       "\n",
       "         S100  \n",
       "Rv0239  100.0  \n",
       "Rv0238  289.0  \n",
       "Rv1322  138.0  \n",
       "Rv2928  287.0  \n",
       "Rv1324  398.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hs_score_per_locus_sims_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add columns for **gene length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/n/data1/hms/dbmi/farhat/Roger/homoplasy_project/pickled_files/mutational_density_simulations_per_locus/locus_length_dict.pickle', 'rb') as handle:\n",
    "    locus_length_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_length_list = []\n",
    "\n",
    "for gene_i in Hs_score_per_locus_sims_df.index:\n",
    "    gene_i_length = locus_length_dict[gene_i]\n",
    "    gene_length_list.append(gene_i_length)\n",
    "    \n",
    "Hs_score_per_locus_sims_df.loc[:,'gene_length'] = gene_length_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>S7</th>\n",
       "      <th>S8</th>\n",
       "      <th>S9</th>\n",
       "      <th>S10</th>\n",
       "      <th>...</th>\n",
       "      <th>S92</th>\n",
       "      <th>S93</th>\n",
       "      <th>S94</th>\n",
       "      <th>S95</th>\n",
       "      <th>S96</th>\n",
       "      <th>S97</th>\n",
       "      <th>S98</th>\n",
       "      <th>S99</th>\n",
       "      <th>S100</th>\n",
       "      <th>gene_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rv0239</th>\n",
       "      <td>82.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>...</td>\n",
       "      <td>109.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rv0238</th>\n",
       "      <td>249.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rv1322</th>\n",
       "      <td>137.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>145.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rv2928</th>\n",
       "      <td>351.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>...</td>\n",
       "      <td>310.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rv1324</th>\n",
       "      <td>379.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>...</td>\n",
       "      <td>394.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           S1     S2     S3     S4     S5     S6     S7     S8     S9    S10  \\\n",
       "Rv0239   82.0   89.0   96.0  115.0  107.0  103.0  114.0   85.0   93.0  108.0   \n",
       "Rv0238  249.0  294.0  279.0  268.0  235.0  261.0  244.0  250.0  290.0  253.0   \n",
       "Rv1322  137.0  139.0  120.0  127.0  118.0  139.0  146.0  133.0  120.0  140.0   \n",
       "Rv2928  351.0  341.0  294.0  324.0  334.0  322.0  295.0  336.0  332.0  314.0   \n",
       "Rv1324  379.0  361.0  429.0  359.0  395.0  398.0  391.0  407.0  405.0  390.0   \n",
       "\n",
       "           ...         S92    S93    S94    S95    S96    S97    S98    S99  \\\n",
       "Rv0239     ...       109.0   97.0   98.0   93.0  106.0   83.0  102.0   92.0   \n",
       "Rv0238     ...       240.0  258.0  288.0  313.0  276.0  288.0  276.0  282.0   \n",
       "Rv1322     ...       145.0  119.0  134.0  125.0  125.0  135.0  135.0  138.0   \n",
       "Rv2928     ...       310.0  338.0  337.0  313.0  321.0  312.0  337.0  328.0   \n",
       "Rv1324     ...       394.0  403.0  417.0  387.0  416.0  370.0  402.0  363.0   \n",
       "\n",
       "         S100  gene_length  \n",
       "Rv0239  100.0          234  \n",
       "Rv0238  289.0          615  \n",
       "Rv1322  138.0          297  \n",
       "Rv2928  287.0          740  \n",
       "Rv1324  398.0          915  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hs_score_per_locus_sims_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Hs_score_per_locus_sims_df.mean(axis=1) / Hs_score_per_locus_sims_df.gene_length.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rv0239     0.441863\n",
       "Rv0238     0.436674\n",
       "Rv1322     0.436877\n",
       "Rv2928     0.438908\n",
       "Rv1324     0.436801\n",
       "Rv1321     0.438944\n",
       "Rv0231     0.439721\n",
       "Rv0233     0.441303\n",
       "Rv0232     0.436131\n",
       "Rv2929     0.444267\n",
       "Rv0042c    0.436828\n",
       "Rv2352c    0.435433\n",
       "Rv0965c    0.437082\n",
       "Rv1323     0.438091\n",
       "Rv0693     0.436915\n",
       "Rv1567c    0.438840\n",
       "Rv3534c    0.437233\n",
       "Rv3256c    0.437662\n",
       "Rv0878c    0.436585\n",
       "Rv0422c    0.437554\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42326732673267325"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43736258246365517"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4538613861386138"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4486131403607093"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(np.array(x), 99.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] Re-run simulation N times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = 100\n",
    "homoplasy_score_distribution_per_run = {}\n",
    "for sim_i in range(1, num_sims+1):\n",
    "\n",
    "    mutation_events_per_pos_dict = Counter()\n",
    "\n",
    "    for isolate_group_i in isolate_group_list:\n",
    "\n",
    "        num_mutations_per_branch_series_i, mutation_events_per_pos_dict_i = get_mutation_events_from_tree_branches(num_sites_to_construct_tree_dict[isolate_group_i], isolate_group_i)\n",
    "        mutation_events_per_pos_dict = mutation_events_per_pos_dict + mutation_events_per_pos_dict_i\n",
    "\n",
    "    # distribution of homoplasy score across all mutant alleles\n",
    "    mutation_events_per_pos_series = pd.Series(mutation_events_per_pos_dict)\n",
    "    homoplasy_score_per_mutation = pd.Series(Counter(mutation_events_per_pos_series))\n",
    "\n",
    "    # store distribution of homoplasy scores in dict\n",
    "    homoplasy_score_distribution_per_run['sim_' + str(sim_i)] = homoplasy_score_per_mutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results of simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/n/data1/hms/dbmi/farhat/Roger/homoplasy_project/pickled_files/SNV_homoplasy_score_distribution_simluation_counts.pickle', 'wb') as handle:\n",
    "    pickle.dump(homoplasy_score_distribution_per_run, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load dictionary of **homoplasy score** counts for each simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/n/data1/hms/dbmi/farhat/Roger/homoplasy_project/pickled_files/SNV_homoplasy_score_distribution_simluation_counts.pickle', 'rb') as handle:\n",
    "    homoplasy_score_distribution_per_run = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
