{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a virtual_env to run **InSilicoSeq** (called *insilicoseq_virtualenv* with python 3.7), have to install\n",
    "- pandas (conda install -c anaconda pandas)\n",
    "- numpy (conda install -c anaconda numpy)\n",
    "- biopython (conda install -c conda-forge biopython)\n",
    "- jupyter (conda install -c anaconda jupyter)\n",
    "- insilicoseq (conda install -c bioconda insilicoseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Bio\n",
    "\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.Blast.Applications import NcbiblastnCommandline\n",
    "from Bio.Blast import NCBIXML\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Seq import MutableSeq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from Bio import pairwise2\n",
    "from Bio import SeqIO\n",
    "from Bio.Graphics import GenomeDiagram\n",
    "from Bio.SeqUtils import GC\n",
    "from Bio.Align.Applications import MuscleCommandline\n",
    "from StringIO import StringIO\n",
    "from Bio import AlignIO\n",
    "from Bio.Align import AlignInfo\n",
    "from Bio.Seq import MutableSeq\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from shutil import copy\n",
    "import pickle\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### specify the tag for the genome assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_assemblies = ['RW-TB008', 'N1274', 'N1272', 'N1202', 'N1177', 'N1176', 'N0155', \n",
    "                     'N0153', 'N0145', 'N0091', 'N0072', 'N0054', 'N0004', 'M0017522_5', \n",
    "                     'M0016737_0', 'M0016395_7', 'M0014888_3', 'M0011368_9', 'M0010874_7', \n",
    "                     'M0003941_3', 'DNA120', 'DNA091', 'DNA086', 'DNA075', 'DNA044', 'DNA020', \n",
    "                     'DNA019_Rose', 'AZE_02_042', '02_R1896', '02_R1708', '02_R1179', '02_R0894', '01_R1430']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genome_assemblies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through each Mtb assembly\n",
    "for Mtb_genome_tag in genome_assemblies:\n",
    "\n",
    "    # load the dataframe with the seq differences between H37Rv and assembly, \n",
    "    # alter assembly HT/SSR sequence where needed and generate FASTA file\n",
    "    ##########################################################################################\n",
    "    ##########################################################################################\n",
    "    # load the H37Rv-assembly mappings with the sequences to alter in each HT/SSR region\n",
    "    repeat_region_mapping_df =  pd.read_pickle('/n/data1/hms/dbmi/farhat/Roger/homoplasy_project/HT_SSR_recall_sims/H37Rv_to_assembly_mappings_2/HT_SSR_'+Mtb_genome_tag+'_mappings.pkl')\n",
    "    \n",
    "    # re-sort to order HT/SSR regions in \n",
    "    repeat_region_mapping_df.sort_values(by='chromStart', ascending=True, inplace=True)\n",
    "    repeat_region_mapping_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # load FASTA of complete assembly sequence\n",
    "    Mtb_genome = '/n/data1/hms/dbmi/farhat/Roger/homoplasy_project/HT_SSR_recall_sims/220829.36CI.ForRoger.Asms/'+Mtb_genome_tag+'.fna'\n",
    "    for Mtb_genome in SeqIO.parse(Mtb_genome, \"fasta\"):\n",
    "        Mtb_genome.seq.alphabet = IUPAC.unambiguous_dna\n",
    "\n",
    "    # FASTA WITH ALTERED ASSEMBLY GENOME\n",
    "\n",
    "    # copy assembly sequnece\n",
    "    assembly_with_variants = Mtb_genome.seq.tomutable()\n",
    "\n",
    "    # iterate through HT/SSR regions and change assembly where indicated\n",
    "    for repeat_region_i in repeat_region_mapping_df.index:\n",
    "        \n",
    "        repeat_region_assembly_start = repeat_region_mapping_df.loc[repeat_region_i, 'assembly_chromStart']\n",
    "        repeat_region_assembly_end = repeat_region_mapping_df.loc[repeat_region_i, 'assembly_chromEnd']\n",
    "        polyNT = repeat_region_mapping_df.loc[repeat_region_i,'assembly_polyNT']\n",
    "        added_seq = repeat_region_mapping_df.loc[repeat_region_i,'add_seq_into_assembly']\n",
    "\n",
    "        # check to see if HT/SSR region needs sequence altered\n",
    "        if (added_seq != 'None') and (added_seq != 'no match') and (type(repeat_region_assembly_start) != list):\n",
    "\n",
    "            # change HT/SSR seqs where necessary\n",
    "            assembly_with_variants[int(repeat_region_assembly_start):int(repeat_region_assembly_end)] = polyNT + added_seq # add \"insertion\"\n",
    "            \n",
    "            ##########################################################################################\n",
    "            # update coordinates for HT/SSR repeat regions\n",
    "            ##########################################################################################\n",
    "            # add +bp to HT/SSR region assembly start & end coordinates if an insertion is added and shift sequences downstream by length of added seq\n",
    "            updated_repeat_region_start_list = []\n",
    "            updated_repeat_region_end_list = []\n",
    "            for repeat_region_i, repeat_region_start, repeat_region_end in zip(repeat_region_mapping_df.index, repeat_region_mapping_df.assembly_chromStart, repeat_region_mapping_df.assembly_chromEnd):\n",
    "\n",
    "                # check to make sure not np.nan (none mapped region)\n",
    "                if (type(repeat_region_start) != list) and (np.isnan(repeat_region_start) == True):\n",
    "                    updated_repeat_region_start_list.append(np.nan)\n",
    "                    updated_repeat_region_end_list.append(np.nan)\n",
    "                \n",
    "                # repeat region from H37Rv mapped to multiple places in assembly\n",
    "                elif type(repeat_region_start) == list:\n",
    "                    repeat_region_start_sublist = []\n",
    "                    repeat_region_end_sublist = []\n",
    "                    \n",
    "                    for repeat_region_start_i, repeat_region_end_i in zip(repeat_region_start,repeat_region_end):\n",
    "                        \n",
    "                        if repeat_region_start_i > repeat_region_assembly_start:\n",
    "                            repeat_region_start_sublist.append(repeat_region_start_i + len(added_seq))\n",
    "                        else:\n",
    "                            repeat_region_start_sublist.append(repeat_region_start_i)\n",
    "                        \n",
    "                        if repeat_region_end_i > repeat_region_assembly_end:\n",
    "                            repeat_region_end_sublist.append(repeat_region_end_i + len(added_seq))\n",
    "                        else:\n",
    "                            repeat_region_end_sublist.append(repeat_region_end_i)\n",
    "                            \n",
    "                    updated_repeat_region_start_list.append(repeat_region_start_sublist)\n",
    "                    updated_repeat_region_end_list.append(repeat_region_end_sublist)\n",
    "                    \n",
    "                # add +bp to any position downstream of chromStart for assembly repeat region\n",
    "                else:\n",
    "                    if repeat_region_start > repeat_region_assembly_start:\n",
    "                        updated_repeat_region_start_list.append(repeat_region_start + len(added_seq))\n",
    "                    else:\n",
    "                        updated_repeat_region_start_list.append(repeat_region_start)\n",
    "                        \n",
    "                    if repeat_region_end > repeat_region_assembly_start:\n",
    "                        updated_repeat_region_end_list.append(repeat_region_end + len(added_seq))\n",
    "                    else:\n",
    "                        updated_repeat_region_end_list.append(repeat_region_end)\n",
    "                        \n",
    "            # update start/end positions of repeat regions in assemblies\n",
    "            repeat_region_mapping_df.loc[:, 'assembly_chromStart'] = updated_repeat_region_start_list\n",
    "            repeat_region_mapping_df.loc[:, 'assembly_chromEnd'] = updated_repeat_region_end_list\n",
    "                \n",
    "        # might have to account for \"duplications\" where H37Rv sub-sequence mapped to multiple place in H37Rv\n",
    "        if (added_seq != 'None') and (added_seq != 'no match') and (type(repeat_region_assembly_start) == list):\n",
    "            \n",
    "            # iterate through each region of assembly that H37Rv mapped to, change sequence and update coordinates accordingly\n",
    "            for repeat_region_assembly_start_i, repeat_region_assembly_end_i in zip(repeat_region_assembly_start, repeat_region_assembly_end):\n",
    "            \n",
    "                # change HT/SSR seqs where necessary\n",
    "                assembly_with_variants[int(repeat_region_assembly_start_i):int(repeat_region_assembly_end_i)] = polyNT + added_seq # add \"insertion\"\n",
    "\n",
    "                ##########################################################################################\n",
    "                # update coordinates for HT/SSR repeat regions\n",
    "                ##########################################################################################\n",
    "                # add +bp to HT/SSR region assembly start & end coordinates if an insertion is added and shift sequences downstream by length of added seq\n",
    "                updated_repeat_region_start_list = []\n",
    "                updated_repeat_region_end_list = []\n",
    "                for repeat_region_i, repeat_region_start, repeat_region_end in zip(repeat_region_mapping_df.index, repeat_region_mapping_df.assembly_chromStart, repeat_region_mapping_df.assembly_chromEnd):\n",
    "\n",
    "                    # check to make sure not np.nan (none mapped region)\n",
    "                    if (type(repeat_region_start) != list) and (np.isnan(repeat_region_start) == True):\n",
    "                        updated_repeat_region_start_list.append(np.nan)\n",
    "                        updated_repeat_region_end_list.append(np.nan)\n",
    "\n",
    "                    # repeat region from H37Rv mapped to multiple places in assembly\n",
    "                    elif type(repeat_region_start) == list:\n",
    "                        repeat_region_start_sublist = []\n",
    "                        repeat_region_end_sublist = []\n",
    "\n",
    "                        for repeat_region_start_i, repeat_region_end_i in zip(repeat_region_start,repeat_region_end):\n",
    "\n",
    "                            if repeat_region_start_i > repeat_region_assembly_start_i:\n",
    "                                repeat_region_start_sublist.append(repeat_region_start_i + len(added_seq))\n",
    "                            else:\n",
    "                                repeat_region_start_sublist.append(repeat_region_start_i)\n",
    "\n",
    "                            if repeat_region_end_i > repeat_region_assembly_end_i:\n",
    "                                repeat_region_end_sublist.append(repeat_region_end_i + len(added_seq))\n",
    "                            else:\n",
    "                                repeat_region_end_sublist.append(repeat_region_end_i)\n",
    "\n",
    "                        updated_repeat_region_start_list.append(repeat_region_start_sublist)\n",
    "                        updated_repeat_region_end_list.append(repeat_region_end_sublist)\n",
    "\n",
    "                    # add +bp to any position downstream of chromStart for assembly repeat region\n",
    "                    else:\n",
    "                        if repeat_region_start > repeat_region_assembly_start_i:\n",
    "                            updated_repeat_region_start_list.append(repeat_region_start + len(added_seq))\n",
    "                        else:\n",
    "                            updated_repeat_region_start_list.append(repeat_region_start)\n",
    "\n",
    "                        if repeat_region_end > repeat_region_assembly_start_i:\n",
    "                            updated_repeat_region_end_list.append(repeat_region_end + len(added_seq))\n",
    "                        else:\n",
    "                            updated_repeat_region_end_list.append(repeat_region_end)\n",
    "\n",
    "                # update start/end positions of repeat regions in assemblies\n",
    "                repeat_region_mapping_df.loc[:, 'assembly_chromStart'] = updated_repeat_region_start_list\n",
    "                repeat_region_mapping_df.loc[:, 'assembly_chromEnd'] = updated_repeat_region_end_list\n",
    "\n",
    "    # convert mutable seq back to normal sequence\n",
    "    assembly_with_variants = assembly_with_variants.toseq()\n",
    "\n",
    "    # store in SeqRecord with strain ID\n",
    "    assembly_with_variants = SeqRecord(assembly_with_variants , id = Mtb_genome_tag)\n",
    "    \n",
    "    # store altered assembly as a FASTA file\n",
    "    assembly_dir = '/n/data1/hms/dbmi/farhat/Roger/homoplasy_project/HT_SSR_recall_sims/altered_assemblies/'\n",
    "    SeqIO.write(assembly_with_variants, assembly_dir + Mtb_genome_tag + \"_altered_seq.fasta\", \"fasta\")\n",
    "    \n",
    "    # save updated mappings as a pickled file\n",
    "    repeat_region_mapping_df.to_pickle('/n/data1/hms/dbmi/farhat/Roger/homoplasy_project/HT_SSR_recall_sims/H37Rv_to_assembly_mappings_3/' + 'HT_SSR_'+Mtb_genome_tag+'_mappings.pkl')\n",
    "    ##########################################################################################\n",
    "    ##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slurmpy import Slurm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896207\n",
      "submitted: Submitted batch job 61896208\n",
      "submitted: Submitted batch job 61896209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISS_RW-TB008 : 61896207\n",
      "ISS_N1274 : 61896208\n",
      "ISS_N1272 : 61896209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896210\n",
      "submitted: Submitted batch job 61896211\n",
      "submitted: Submitted batch job 61896212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISS_N1202 : 61896210\n",
      "ISS_N1177 : 61896211\n",
      "ISS_N1176 : 61896212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896213\n",
      "submitted: Submitted batch job 61896214\n",
      "submitted: Submitted batch job 61896215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISS_N0155 : 61896213\n",
      "ISS_N0153 : 61896214\n",
      "ISS_N0145 : 61896215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896216\n",
      "submitted: Submitted batch job 61896217\n",
      "submitted: Submitted batch job 61896218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISS_N0091 : 61896216\n",
      "ISS_N0072 : 61896217\n",
      "ISS_N0054 : 61896218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896219\n",
      "submitted: Submitted batch job 61896220\n",
      "submitted: Submitted batch job 61896221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISS_N0004 : 61896219\n",
      "ISS_M0017522_5 : 61896220\n",
      "ISS_M0016737_0 : 61896221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896222\n",
      "submitted: Submitted batch job 61896223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISS_M0016395_7 : 61896222\n",
      "ISS_M0014888_3 : 61896223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896224\n",
      "submitted: Submitted batch job 61896225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISS_M0011368_9 : 61896224\n",
      "ISS_M0010874_7 : 61896225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896226\n",
      "submitted: Submitted batch job 61896227\n",
      "submitted: Submitted batch job 61896228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISS_M0003941_3 : 61896226\n",
      "ISS_DNA120 : 61896227\n",
      "ISS_DNA091 : 61896228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896229\n",
      "submitted: Submitted batch job 61896230\n",
      "submitted: Submitted batch job 61896231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISS_DNA086 : 61896229\n",
      "ISS_DNA075 : 61896230\n",
      "ISS_DNA044 : 61896231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896232\n",
      "submitted: Submitted batch job 61896233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISS_DNA020 : 61896232\n",
      "ISS_DNA019_Rose : 61896233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896234\n",
      "submitted: Submitted batch job 61896235\n",
      "submitted: Submitted batch job 61896236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISS_AZE_02_042 : 61896234\n",
      "ISS_02_R1896 : 61896235\n",
      "ISS_02_R1708 : 61896236\n",
      "ISS_02_R1179 : 61896237\n",
      "ISS_02_R0894 : 61896238\n",
      "ISS_01_R1430 : 61896240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896237\n",
      "submitted: Submitted batch job 61896238\n",
      "submitted: Submitted batch job 61896240\n"
     ]
    }
   ],
   "source": [
    "# simulate reads from the altered assembly to generate FASTQ files\n",
    "##########################################################################################\n",
    "##########################################################################################\n",
    "\n",
    "assembly_dir = '/n/data1/hms/dbmi/farhat/Roger/homoplasy_project/HT_SSR_recall_sims/altered_assemblies/'\n",
    "\n",
    "# iterate through each Mtb assembly\n",
    "for Mtb_genome_tag in genome_assemblies:\n",
    "\n",
    "    #### prepare file and directory paths ####\n",
    "\n",
    "    #input file paths\n",
    "    altered_assembly_fasta = assembly_dir + Mtb_genome_tag + \"_altered_seq.fasta\" #directory/filename of reference sequence with variants\n",
    "\n",
    "    #create directory to store fastq files\n",
    "    fastq_file_dir = '/n/data1/hms/dbmi/farhat/Roger/homoplasy_project/HT_SSR_recall_sims/simulated_fastq_files_from_InSilicoSeq_for_altered_seq/'\n",
    "    if not os.path.exists(fastq_file_dir + Mtb_genome_tag):\n",
    "        os.makedirs(fastq_file_dir + Mtb_genome_tag)\n",
    "\n",
    "    #output directories\n",
    "    out_dir = fastq_file_dir + Mtb_genome_tag + '/' + Mtb_genome_tag\n",
    "    SLURM_log_dir = '/n/data1/hms/dbmi/farhat/Roger/homoplasy_project/HT_SSR_recall_sims/simulated_fastq_files_from_InSilicoSeq_for_altered_seq/O2_SLURM_logs'\n",
    "\n",
    "    #### construct job to submit to O2 ####\n",
    "\n",
    "    #store all commands in a list\n",
    "    commands_list = []\n",
    "\n",
    "    #load virtual environment for SNPPar\n",
    "    commands_list.append( 'set +eu' )\n",
    "    commands_list.append( 'source activate insilicoseq_virtualenv' )\n",
    "    commands_list.append( 'set -eu' )\n",
    "\n",
    "    #run InSilicoSeq\n",
    "\n",
    "    #change directory to one with all of the files\n",
    "    ## parameters\n",
    "    ## -ss HS20 ; Illumina HiSeq\n",
    "    ## -l 100 ; read length of 100\n",
    "    ## -f 100 ; mean coverage of 100x\n",
    "    ## -p ; paired end reads\n",
    "    ## -m 200; 200 bp mean size of DNA fragments for paired-end simulations\n",
    "    ## -s 25; 25 bp standard deviation of DNA fragment size for paired-end simulations\n",
    "\n",
    "    ## art_command = ART + ' -ss HS20 -i ' + altered_assembly_fasta + ' -o ' + fastq_directory + ' -l 100 -f 100 -p -m 200 -s 25'\n",
    "    ## C = LN/G; 100 = (125 x N)/(4411532), so N = (100 x 4411532) / 125 = 3,529,225.6 ~ 3.5 million reads\n",
    "\n",
    "    commands_list.append( 'iss generate --n_reads 3.5M --cpus 4 --genomes {0} --model hiseq --output {1}'.format(altered_assembly_fasta, out_dir) )\n",
    "\n",
    "    #### SUBMIT the job to O2 ####\n",
    "\n",
    "    #append all commands in a single string to be submitted as a job\n",
    "    read_sim_job = ''\n",
    "    for command_i in commands_list:\n",
    "        read_sim_job = read_sim_job + '\\n' + command_i\n",
    "\n",
    "    #directory where you want output + error files\n",
    "    os.chdir(SLURM_log_dir)\n",
    "\n",
    "    job_name = 'ISS_' + Mtb_genome_tag\n",
    "\n",
    "    #submit SNPPar job via SLURM\n",
    "    s = Slurm(job_name , {'partition':'short', 'account':'farhat', 'N':'1' , 'n':'1' , 'c':'4' , 't':'0-1:30:00' , 'mem':'32G' , 'mail-type':'FAIL' , 'mail-user':'roger_vargas@g.harvard.edu'})\n",
    "\n",
    "    #submits the job\n",
    "    job_id = s.run(read_sim_job)\n",
    "\n",
    "    print job_name  + ' : ' +  str(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
