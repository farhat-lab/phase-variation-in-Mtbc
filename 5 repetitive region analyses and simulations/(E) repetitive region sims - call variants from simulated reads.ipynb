{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import vcf\n",
    "import shutil\n",
    "from slurmpy import Slurm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### [1] process reads and run *pilon* to get variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Launch_SmallPipe_Altered_assembly(Mtb_genome_tag):\n",
    "    \n",
    "    ###############################################################################################################\n",
    "    ###################################### Create Directories & Get File Paths ####################################\n",
    "    ###############################################################################################################\n",
    "\n",
    "    #paths & names for simulated fastq files\n",
    "    fqf1 = '/n/data1/hms/dbmi/farhat/Roger/homoplasy_project/HT_SSR_recall_sims/simulated_fastq_files_from_InSilicoSeq_for_altered_seq/' + Mtb_genome_tag + '/' + Mtb_genome_tag + '_R1.fastq'\n",
    "    fqf2 = '/n/data1/hms/dbmi/farhat/Roger/homoplasy_project/HT_SSR_recall_sims/simulated_fastq_files_from_InSilicoSeq_for_altered_seq/' + Mtb_genome_tag + '/' + Mtb_genome_tag + '_R2.fastq'\n",
    "    \n",
    "    assembly_dir = '/n/data1/hms/dbmi/farhat/Roger/homoplasy_project/HT_SSR_recall_sims/process_sim_reads_and_call_variants/'\n",
    "    os.chdir(assembly_dir)\n",
    "    \n",
    "    # create directory where intermediary files and output will be stored\n",
    "    assembly_dir_with_files = assembly_dir + Mtb_genome_tag\n",
    "    if os.path.exists(assembly_dir_with_files):\n",
    "        shutil.rmtree(assembly_dir_with_files)\n",
    "        os.makedirs(assembly_dir_with_files)\n",
    "    elif not os.path.exists(assembly_dir_with_files):\n",
    "        os.makedirs(assembly_dir_with_files)\n",
    "\n",
    "    #H37Rv Reference Genome Path\n",
    "    RefGen = assembly_dir_with_files + '/RefGen/TBRefGen.fasta' #H37Rv reference\n",
    "\n",
    "    #create directory to store Reference Genome and corresponding Index Files\n",
    "    RefGen_dir = assembly_dir_with_files + '/' + 'RefGen'\n",
    "    if os.path.exists(RefGen_dir):\n",
    "        shutil.rmtree(RefGen_dir)\n",
    "        os.makedirs(RefGen_dir)\n",
    "    elif not os.path.exists(RefGen_dir):\n",
    "        os.makedirs(RefGen_dir)\n",
    "\n",
    "    #create directory to store pilon VCF, prinseq & Qualimap logs\n",
    "    out_dir = assembly_dir_with_files + '/' + 'SmPipe_output_ALT_assembly'\n",
    "    if os.path.exists(out_dir):\n",
    "        shutil.rmtree(out_dir)\n",
    "        os.makedirs(out_dir)\n",
    "    elif not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    #create directory to store intermediary files (trimmed fastq, SAM, sorted BAM, sorted BAM w/ duplicates removed)\n",
    "    temp_dir = assembly_dir_with_files + '/' + 'temp_for_intermediary_steps'\n",
    "    if os.path.exists(temp_dir):\n",
    "        shutil.rmtree(temp_dir)\n",
    "        os.makedirs(temp_dir)\n",
    "    elif not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "\n",
    "    #create directory to store O2 SLURM logs\n",
    "    SLURM_log_dir = out_dir + '/' + 'O2_SLURM_logs'\n",
    "    if os.path.exists(SLURM_log_dir):\n",
    "        shutil.rmtree(SLURM_log_dir)\n",
    "        os.makedirs(SLURM_log_dir)\n",
    "    elif not os.path.exists(SLURM_log_dir):\n",
    "        os.makedirs(SLURM_log_dir)\n",
    "\n",
    "    ###############################################################################################################\n",
    "    ######################################## Construct job to submit to O2 ########################################\n",
    "    ###############################################################################################################\n",
    "\n",
    "    #store all commands in a list\n",
    "    commands_list = []\n",
    "\n",
    "    #change directory to 1 with fastq files\n",
    "    commands_list.append( 'cd ' + assembly_dir_with_files )\n",
    "\n",
    "    ###################################\n",
    "    ### Load Necessary Modules ########\n",
    "    ###################################\n",
    "\n",
    "    #load perl\n",
    "    commands_list.append( 'module load perl/5.24.0' )\n",
    "\n",
    "    #load java\n",
    "    commands_list.append( 'module load java/jdk-1.8u112' )\n",
    "\n",
    "    #load BWA\n",
    "    commands_list.append( 'module load bwa/0.7.15' )\n",
    "\n",
    "    #load Samtools\n",
    "    commands_list.append( 'module load samtools/1.3.1' )\n",
    "\n",
    "    #load BCFtools\n",
    "    commands_list.append( 'module load bcftools/1.3.1' )\n",
    "\n",
    "    #load Picard\n",
    "    commands_list.append( 'module load picard/2.8.0' )\n",
    "\n",
    "    #copy reference genome over to RefGen folder\n",
    "    commands_list.append( 'cp /n/data1/hms/dbmi/farhat/bin/work-horse/bin/h37rv.fasta RefGen/TBRefGen.fasta' )\n",
    "\n",
    "    #change directory to RefGen folder\n",
    "    commands_list.append( 'cd RefGen' )\n",
    "\n",
    "    ###################################\n",
    "    ### Create Index Files for H37Rv ##\n",
    "    ###################################\n",
    "    commands_list.append( 'samtools faidx TBRefGen.fasta' )\n",
    "    commands_list.append( 'bwa index TBRefGen.fasta' )\n",
    "\n",
    "    #Go back up a directory\n",
    "    commands_list.append( 'cd ..' )\n",
    "\n",
    "    ####################################\n",
    "    ### PRINSEQ (trim reads) ##########\n",
    "    ###################################\n",
    "\n",
    "    #create directory for prinseq in output directory\n",
    "    commands_list.append( 'mkdir ' + out_dir + '/prinseq' )\n",
    "\n",
    "    commands_list.append( 'perl /n/data1/hms/dbmi/farhat/bin/prinseq-lite-0.20.4/prinseq-lite.pl -fastq {0} -fastq2 {1} -out_format 3 -out_good {2}/{3}-trimmed -out_bad null -log {4}/{3}-trimmed.log -min_qual_mean 20 -verbose'.format(fqf1, fqf2, temp_dir, Mtb_genome_tag , out_dir+'/prinseq') )\n",
    "\n",
    "    #use newly trimmed fastq files now\n",
    "    fqf1 = temp_dir + '/{}'.format(Mtb_genome_tag) + '-trimmed_1.fastq'\n",
    "    fqf2 = temp_dir + '/{}'.format(Mtb_genome_tag) + '-trimmed_2.fastq'\n",
    "\n",
    "    ######################################\n",
    "    ### BWA (align reads to reference) ###\n",
    "    ######################################\n",
    "\n",
    "    #create SAM file\n",
    "    samfile = temp_dir + '/{}.sam'.format(Mtb_genome_tag)\n",
    "\n",
    "    #run BWA\n",
    "    commands_list.append( 'bwa mem -M {3} {0} {1} > {2}'.format(fqf1 , fqf2 , samfile , RefGen) )\n",
    "\n",
    "    #####################################\n",
    "    ### PICARD (sort & convert to BAM) ##\n",
    "    #####################################\n",
    "\n",
    "    #create BAM file\n",
    "    bamfile = temp_dir + '/{0}.sorted.bam'.format(Mtb_genome_tag)\n",
    "\n",
    "    commands_list.append( 'java -Xmx16G -jar /n/data1/hms/dbmi/farhat/bin/picard/picard/build/libs/picard.jar SortSam INPUT={0} OUTPUT={1} SORT_ORDER=coordinate'.format(samfile, bamfile) )\n",
    "\n",
    "    ####################################\n",
    "    ### PICARD (remove duplicates) ####\n",
    "    ###################################\n",
    "\n",
    "    #create BAM file with removed duplicates\n",
    "    drbamfile = bamfile.replace(\".bam\", \".duprem.bam\")\n",
    "\n",
    "    #remove duplicates from BAM file\n",
    "    commands_list.append( \"java -Xmx32G -jar /n/data1/hms/dbmi/farhat/bin/picard/picard/build/libs/picard.jar MarkDuplicates I={0} O={1} REMOVE_DUPLICATES=true M={2} ASSUME_SORT_ORDER=coordinate\".format(bamfile, drbamfile, drbamfile[:-4]+'.metrics') )\n",
    "\n",
    "    ####################################\n",
    "    ### SAMTOOLS (to index BAM file) ###\n",
    "    ####################################\n",
    "\n",
    "    commands_list.append( \"samtools index {0}\".format(drbamfile) )\n",
    "\n",
    "    ######################################\n",
    "    ### QUALIMAP (quality of BAM file) ###\n",
    "    ######################################\n",
    "\n",
    "    #store quality report, pilon VCF & lineage call information all in Output directory\n",
    "    commands_list.append( 'cd ' + out_dir )\n",
    "    commands_list.append( 'mkdir QualiMap' ) #make a folder for pilon output in output directory\n",
    "    commands_list.append( 'unset DISPLAY' ) #unset JAVA virtual machine variable [http://qualimap.bioinfo.cipf.es/doc_html/faq.html]\n",
    "    commands_list.append( \"/n/data1/hms/dbmi/farhat/bin/qualimap_v2.2.1/qualimap bamqc -bam {0} --outdir {1} --outfile {2}.pdf --outformat PDF\".format(drbamfile, out_dir+'/QualiMap', Mtb_genome_tag+'_stats') )\n",
    "\n",
    "    ###################################\n",
    "    ### PILON (call variants) #########\n",
    "    ###################################\n",
    "\n",
    "    #store quality report, pilon VCF & lineage call information all in Output directory\n",
    "    commands_list.append( 'mkdir pilon' ) #make a folder for pilon output in output directory\n",
    "    out_pilon_dir = out_dir + '/pilon/' #variable for pilon output path\n",
    "\n",
    "    commands_list.append( 'java -Xmx32G -jar /n/data1/hms/dbmi/farhat/bin/pilon/pilon-1.22.jar --genome {0} --bam {1} --output {2} --outdir {3} --variant'.format(RefGen, drbamfile, Mtb_genome_tag, out_pilon_dir) )\n",
    "\n",
    "    ###################################\n",
    "    ### DELETE UNNECESSSRY FILES ######\n",
    "    ###################################\n",
    "    \n",
    "    #delete directory containing following files\n",
    "    # trimmed fastq files\n",
    "    # fastq trimming log\n",
    "    # SAM file produced by running BWA on original or trimmed fastq\n",
    "    # sorted BAM file\n",
    "    # sorted BAM file with removed duplicates\n",
    "    # output text from picard after discarding duplicates\n",
    "    # index file corresponding to sorted BAM file with or without removed duplicates\n",
    "    ## commands_list.append( 'rm -rf {}'.format(temp_dir) )\n",
    "\n",
    "    #delete RefGen\n",
    "    commands_list.append( 'rm -rf {}'.format(RefGen_dir) )\n",
    "    \n",
    "    #delete fastq files simulate off of Altered Reference Genome\n",
    "    ## commands_list.append( 'rm -rf {}'.format(assembly_dir_with_files + '/' + 'fastq_files_from_ART_for_ALT_RefGenome/') )\n",
    "\n",
    "    #delete PASS CALLS (supporting Reference) and AMBIGUOUS CALLS from VCF file that came from Pilon variant calling\n",
    "    commands_list.append( 'python /n/data1/hms/dbmi/farhat/Roger/inhost_TB_dynamics_project/python_scripts/reduce-pilon-vcf-size.py ' + out_dir + '/pilon/' + Mtb_genome_tag + '.vcf' )\n",
    "    \n",
    "\n",
    "    ###############################################################################################################\n",
    "    ######################################## SUBMIT the job to O2 #################################################\n",
    "    ###############################################################################################################\n",
    "\n",
    "    #append all commands in a single string to be submitted as a job\n",
    "    SmallPipe_job = ''\n",
    "    for command_i in commands_list:\n",
    "\n",
    "        SmallPipe_job = SmallPipe_job + '\\n' + command_i\n",
    "\n",
    "\n",
    "    #directory where you want output + error files\n",
    "    os.chdir(SLURM_log_dir)\n",
    "\n",
    "    job_name = 'alt_' + str(Mtb_genome_tag)\n",
    "\n",
    "    #make sure to set run-time much shorter since we're only dealing with 80x coverage\n",
    "    s = Slurm(job_name , {'partition':'short', 'account':'farhat', 'N':'1' , 'n':'1' , 't':'0-3:00:00' , 'mem':'32G' , 'mail-type':'FAIL' , 'mail-user':'roger_vargas@g.harvard.edu'})\n",
    "\n",
    "    #submits the job\n",
    "    job_id = s.run(SmallPipe_job)\n",
    "\n",
    "    print job_name  + ' : ' +  str(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_assemblies = ['RW-TB008', 'N1274', 'N1272', 'N1202', 'N1177', 'N1176', 'N0155', \n",
    "                     'N0153', 'N0145', 'N0091', 'N0072', 'N0054', 'N0004', 'M0017522_5', \n",
    "                     'M0016737_0', 'M0016395_7', 'M0014888_3', 'M0011368_9', 'M0010874_7', \n",
    "                     'M0003941_3', 'DNA120', 'DNA091', 'DNA086', 'DNA075', 'DNA044', 'DNA020', \n",
    "                     'DNA019_Rose', 'AZE_02_042', '02_R1896', '02_R1708', '02_R1179', '02_R0894', '01_R1430']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genome_assemblies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896882\n",
      "submitted: Submitted batch job 61896883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt_RW-TB008 : 61896882\n",
      "alt_N1274 : 61896883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896884\n",
      "submitted: Submitted batch job 61896885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt_N1272 : 61896884\n",
      "alt_N1202 : 61896885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896886\n",
      "submitted: Submitted batch job 61896887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt_N1177 : 61896886\n",
      "alt_N1176 : 61896887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896888\n",
      "submitted: Submitted batch job 61896889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt_N0155 : 61896888\n",
      "alt_N0153 : 61896889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896890\n",
      "submitted: Submitted batch job 61896891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt_N0145 : 61896890\n",
      "alt_N0091 : 61896891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896892\n",
      "submitted: Submitted batch job 61896893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt_N0072 : 61896892\n",
      "alt_N0054 : 61896893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896894\n",
      "submitted: Submitted batch job 61896895\n",
      "submitted: Submitted batch job 61896896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt_N0004 : 61896894\n",
      "alt_M0017522_5 : 61896895\n",
      "alt_M0016737_0 : 61896896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896897\n",
      "submitted: Submitted batch job 61896898\n",
      "submitted: Submitted batch job 61896899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt_M0016395_7 : 61896897\n",
      "alt_M0014888_3 : 61896898\n",
      "alt_M0011368_9 : 61896899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896900\n",
      "submitted: Submitted batch job 61896901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt_M0010874_7 : 61896900\n",
      "alt_M0003941_3 : 61896901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896902\n",
      "submitted: Submitted batch job 61896903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt_DNA120 : 61896902\n",
      "alt_DNA091 : 61896903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896904\n",
      "submitted: Submitted batch job 61896905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt_DNA086 : 61896904\n",
      "alt_DNA075 : 61896905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896906\n",
      "submitted: Submitted batch job 61896907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt_DNA044 : 61896906\n",
      "alt_DNA020 : 61896907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt_DNA019_Rose : 61896908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896909\n",
      "submitted: Submitted batch job 61896910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt_AZE_02_042 : 61896909\n",
      "alt_02_R1896 : 61896910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt_02_R1708 : 61896911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896912\n",
      "submitted: Submitted batch job 61896914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt_02_R1179 : 61896912\n",
      "alt_02_R0894 : 61896914\n",
      "alt_01_R1430 : 61896915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submitted: Submitted batch job 61896915\n"
     ]
    }
   ],
   "source": [
    "#submit a job for each of the assemblies\n",
    "for Mtb_genome_tag in genome_assemblies:\n",
    "    \n",
    "    Launch_SmallPipe_Altered_assembly(Mtb_genome_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
